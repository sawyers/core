# Adding sidecar containers for app data

Within the Prometheus pantheon of applications, basically the services that are already Prometheus-capable, they have a metrics endpoint that can be reachable, there are some core services within the Kubernetes environment, like the Kubelet or API service, but there are a much larger number of applications that don't already have metrics enabled in a Prometheus-compliant fashion. And that includes plenty of applications. So many of the databases that one might deploy at MySQL, Postgres et cetera, or Redis, for example, but also even some of the underlying resources. And when we initially set up this Prometheus environment, we actually enabled the equivalent of a sidecar application. Now a sidecar in the Kubernetes world is simply a container that lives within a pod that provides additional service. In our case, we're gonna actually just look at a system-level sidecar equivalent, the Node Exporter. So if you do an ls here in this directory, we see we have the data that we need to actually enable the interaction between the sidecar resource and the deployment of that sidecar resource, and the actual Prometheus service gathering itself. And if we look at these resources, so let's have a look here at, we'll do, gonna do a more on the 03-promnode.yml file. There are a number of resources that have to be created just to run within a roles-based environment. And so we see those here, for example our service account, with a role and role binding that are needed, but the more important thing is the fact that we're just deploying this DaemonSet, so this is getting the Node Exporter application running. If we were gonna do this as a sidecar application with another environment, there would be the main application, and then within the containers environment, we would just define our other sidecar application and how it interacts with the main application. That's the first part of this, is understanding how the system interacts. Here, we're actually running through a number of components, including an embedded sidecar. Now this sidecar enables the service access, but within this application. So the node exporter is actually gathering the metrics. The sidecar, in this case, actually exposes those metrics through our roles-based access environment. So even though this isn't the common case of a sidecar model it is exactly the same kind of service. So just to make this a little bit more clear, here under containers, we have one image section. So here at the very top, we can see the containers, colon, and then the hyphen, this separates one container model. In this case, image is the section that gets subsetted within this. And one of the maybe confusing things about a YML document, but it's important to sort of note here, is that once I've created this list of items, basically this is one item, if I go down here at the same level of hierarchy, I find the next equivalent hyphen under containers is actually against name. This is just the variability that is available within YML, but it's actually still providing the exact same capability. So I have here defined two different containers, one that I'm calling out by image name first, one that I'm calling out by name first, but this second one is the one that actually exposes the metrics API that then Prometheus can talk to. And so that's the first thing that happens, is the application has to expose that resource. The second thing that happens, as I continue down through this file, is I have to then take that resource and make it discoverable in the system, and that's part of the Kubernetes environment. And I do that by creating a service that exports that resource. And I'm making sure that I label my service in a specific fashion. Now when we set up our Prometheus environment, we also included a labeling interaction that specifically was looking for the k8s app label. That's an important label in this particular set up of the environment, because that's what's going to connect us to our service monitor, which is the other file that we have here. So again, we did an ls to find the files in the directory, and we're gonna do a more on 09-promnodesm. This is a smaller one, our smaller YML document. This is just creating a service monitor. So here we can see kind is ServiceMonitor. We are going to give it a job label. Job label is important from the Prometheus connection perspective, and more importantly, that the real critical piece here is our selector. We wanna match our k8s app node-exporter label. So once we've done that, this tells the service monitor to go connect this, and the service monitor already knows that it's going to go talk to the Prometheus environment that's effectively the ingesting engine for this, but we also see that we're specifically calling out the endpoint that we wanna talk to. Now the endpoint is also part of that service definition that we had in the other file, and that's what actually connects all these resources together. So once that's been done, we'll actually see this service get discovered within the Prometheus environment, and we can actually see that here by looking under Prometheus dashboard, under service discovery. And we'll see all of the services that are currently being monitored by the Prometheus environment, including our Node Exporter. And this is what actually connects the application, its little sidecar, to expose that resource, the service that connects back to that resource, and then finally Prometheus being able to see those metrics. And actually we can even jump in real quick into the metrics domain here, scroll down through all these different metrics. We find, suddenly, all of these node metrics, and these are the metrics that are being provided by that node exporter. All right, and so if we just execute this, we can see Node Exporter is our service, and we have lots and lots of metrics coming out of that particular system-level information.